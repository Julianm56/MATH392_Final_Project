{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73e67ec2",
   "metadata": {},
   "source": [
    "# Fine Tuning\n",
    "\n",
    "In this notebook we demonstrates how to run the entire experimental pipeline (Hyperparameter Optimization, Final Training, and Evaluation) for a model variation that will be selected in a later cell. We achive this by calling the core functions defined in `hpo.py`, `final_training.py`, and `evaluation.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01861b06",
   "metadata": {},
   "source": [
    "### Selecting a model\n",
    "Due to time contraints we have the models in list that will be ran as batches. This will be changed later. For now please only select one of the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44334059",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP_IDS_TO_RUN = ['resnet_head_aug', 'resnet_mid_noaug', 'mobilenet_head_noaug']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b1685",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP_IDS_TO_RUN = ['resnet_head_noaug', 'mobilenet_mid_aug']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e035afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP_IDS_TO_RUN = ['resnet_mid_aug', 'mobilenet_head_aug', 'mobilenet_mid_noaug']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5457ccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet_head_aug', 'resnet_mid_noaug', 'mobilenet_head_noaug']\n"
     ]
    }
   ],
   "source": [
    "print(SETUP_IDS_TO_RUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9597ee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Will run pipeline for Setups ID: ['resnet_head_aug', 'resnet_mid_noaug', 'mobilenet_head_noaug'] ###\n",
      "Using device: mps\n",
      "Output directories ensured.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import time # For potential timing if desired, though scripts handle internal timing\n",
    "import sys\n",
    "sys.path.append('../scripts/*') \n",
    "\n",
    "# Import shared utilities and configurations \n",
    "import utils\n",
    "import config # Contains HPO_CONFIG_LIST, UNFREEZE_MAPS, output dirs, defaults\n",
    "\n",
    "# Import the core processing functions from our scripts\n",
    "from hpo import perform_hpo_for_setup\n",
    "from final_train import perform_final_training_for_setup\n",
    "from evaluate import perform_evaluation_for_setup\n",
    "\n",
    "# --- Define the Single Setup to Run ---\n",
    "print(f\"### Will run pipeline for Setups ID: {SETUP_IDS_TO_RUN} ###\")\n",
    "\n",
    "# --- Global Parameters for this Run (can override config defaults if needed) ---\n",
    "# These would typically come from argparse in the scripts, here we set them directly\n",
    "# Or, we can rely on defaults set within config.py and the script functions\n",
    "HPO_EPOCHS = config.DEFAULT_HPO_EPOCHS\n",
    "FINAL_TRAIN_EPOCHS = config.DEFAULT_FINAL_TRAIN_EPOCHS\n",
    "PATIENCE = config.DEFAULT_PATIENCE\n",
    "BATCH_SIZE = config.DEFAULT_BATCH_SIZE # Using one batch size for simplicity here, scripts might allow separate\n",
    "\n",
    "# --- Device Setup ---\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Ensure Output Directories Exist ---\n",
    "config.create_output_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75336872",
   "metadata": {},
   "source": [
    "## Stage 1: Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8932051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*5} STAGE 1: Hyperparameter Optimization {'='*5}\")\n",
    "\n",
    "for setup_id in SETUP_IDS_TO_RUN:\n",
    "    print(f\"\\nRunning HPO for setup: {setup_id}\")\n",
    "    hpo_start_time = time.time()\n",
    "\n",
    "    # Call the HPO function from run_hpo.py\n",
    "    best_hpo_params_found = perform_hpo_for_setup(\n",
    "        setup_id=setup_id,\n",
    "        hpo_grid=config.HPO_CONFIG_LIST,\n",
    "        num_epochs_hpo=HPO_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        device=device\n",
    "        # The function saves its outputs to files within config.HPO_DIR\n",
    "    )\n",
    "\n",
    "    hpo_end_time = time.time()\n",
    "    print(f\"\\n{'*'*10} HPO Stage for {setup_id} finished in {(hpo_end_time - hpo_start_time)/60:.2f} minutes {'*'*10}\")\n",
    "\n",
    "    if best_hpo_params_found:\n",
    "        print(f\"Best HPO parameters found for {setup_id}: {best_hpo_params_found}\")\n",
    "        # These are also saved to results/hpo/best_params_{setup_id}.json\n",
    "    else:\n",
    "        print(f\"HPO did not complete successfully or find best parameters for {setup_id}. Cannot proceed.\")\n",
    "        # Consider raising an error or stopping the notebook here if HPO is critical for next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedbae2",
   "metadata": {},
   "source": [
    "## Stage 2: Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "for setup_id in SETUP_IDS_TO_RUN:\n",
    "    if best_hpo_params_found:  # Proceed only if HPO was successful\n",
    "        print(f\"\\n{'='*20} STAGE 2: Final Model Training for {setup_id} {'='*20}\")\n",
    "        final_train_start_time = time.time()\n",
    "\n",
    "        # Call the final training function from run_final_training.py\n",
    "        # It will load the best_params file itself based on setup_id.\n",
    "        saved_model_filepath = perform_final_training_for_setup(\n",
    "            setup_id=setup_id,\n",
    "            max_epochs=FINAL_TRAIN_EPOCHS,\n",
    "            patience=PATIENCE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            device=device\n",
    "            # The function saves its outputs to files within config.FINAL_TRAINING_DIR\n",
    "        )\n",
    "\n",
    "        final_train_end_time = time.time()\n",
    "        print(f\"\\n{'*'*10} Final Training Stage for {setup_id} finished in {(final_train_end_time - final_train_start_time)/60:.2f} minutes {'*'*10}\")\n",
    "\n",
    "        if saved_model_filepath:\n",
    "            print(f\"Best model saved to: {saved_model_filepath}\")\n",
    "            # This path is also saved internally by the function to results/final_training/best_model_{setup_id}.pth\n",
    "        else:\n",
    "            print(f\"Final training did not complete successfully or model was not saved for {setup_id}. Cannot proceed to evaluation.\")\n",
    "    else:\n",
    "        print(f\"\\nSkipping Stage 2: Final Model Training for {setup_id} due to HPO failure or no best parameters found.\")\n",
    "        saved_model_filepath = None  # Ensure it's None if HPO failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd65a8",
   "metadata": {},
   "source": [
    "## Stage 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4cc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for setup_id in SETUP_IDS_TO_RUN:\n",
    "    if saved_model_filepath and os.path.exists(saved_model_filepath):  # Proceed only if final training produced a model\n",
    "        print(f\"\\n{'='*20} STAGE 3: Evaluation for {setup_id} {'='*20}\")\n",
    "        eval_start_time = time.time()\n",
    "\n",
    "        # Call the evaluation function from run_evaluation.py\n",
    "        # It will load the model file itself based on setup_id and config.FINAL_TRAINING_DIR\n",
    "        perform_evaluation_for_setup(\n",
    "            setup_id=setup_id,\n",
    "            device=device\n",
    "            # The function saves its outputs to files within config.EVALUATION_DIR\n",
    "        )\n",
    "\n",
    "        eval_end_time = time.time()\n",
    "        print(f\"\\n{'*'*10} Evaluation Stage for {setup_id} finished in {(eval_end_time - eval_start_time)/60:.2f} minutes {'*'*10}\")\n",
    "        print(f\"\\nEvaluation results (predictions and metrics CSVs) are saved in: {config.EVALUATION_DIR}\")\n",
    "    else:\n",
    "        print(f\"\\nSkipping Stage 3: Evaluation for {setup_id} due to final training failure or model not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math392",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
